# YOLOv10-TensorRT(CUDA预处理)

预处理包括letterbox/BGR转RGB/归一化/hwc转chw等

由于yolov10采用的是nms-free，因此出来的坐标做个映射即可

## 环境依赖
- TensorRT-8.6.1.6
- CUDA-12.1
- OpenCV-4.5.0
- ubuntu-20.04（windows亦可）
- pytorch-2.2.1
- ultralytics-8.2.38



## 第一步: pt转onnx

这一步按`yolo mode=export model=./checkpoints/${model_name}.pt format=onnx dynamic=False simplify=True opset=13`导出即可

## 第二步: onnx转pt

fp32/fp16可以使用trtexec直接进行导出，int8的话掉点太多，不建议使用该方法
```shell
/opt/TensorRT-8.6.1.6/targets/x86_64-linux-gnu/bin/trtexec --onnx=./${model_name}.onnx \
  --saveEngine=./${model_name}_fp16.engine  --fp16  
```



Follow the file [ONNX README](../../tools/quantization/tensorrt/post_training/README.md) to convert the pt model to onnx `yolov6n.onnx`.
**Now don't support end2end onnx model which include the nms plugin**
```shell
python ./deploy/ONNX/export_onnx.py \
    --weights runs/train/yolov6_run_exp/exp1/weights/best_ckpt.pt \
    --img 640 \
    --batch 1

python ./deploy/ONNX/export_onnx.py \
    --weights /home/lzj/04.det/yolov8/runs/detect/train29/weights/best.pt \
    --img 640 \
    --batch 1
```

## Step 2: Prepare serialized engine file

Follow the file [post training README](../../tools/quantization/tensorrt/post_training/README.md) to convert and save the serialized engine file `yolov6.engine`.

```shell
python3 onnx_to_tensorrt.py --model ${ONNX_MODEL} \
        --dtype int8  \
        --max_calibration_size=${MAX_CALIBRATION_SIZE} \
        --calibration-data=${CALIBRATION_DATA} \
        --calibration-cache=${CACHE_FILENAME} \
        --preprocess_func=${PREPROCESS_FUNC} \
        --explicit-batch \
        --verbose

python deploy/TensorRT/my_onnx2trt.py -m /home/lzj/04.det/YOLOv6/runs/train/required_test/yolov6n.onnx -d fp16 --verbose


python onnx_to_trt.py -m yolov10s.onnx -d int8 --verbose --img-size 640 --batch-size 1 --calib-img-dir /home/ubuntu/Downloads/coco_calib_data/
 
``` 

## 第三步: 修改配置项

在include/

```c++
const int num_class = 80;
static const int INPUT_W = 640;
static const int INPUT_H = 640;
static const char* class_names[] = {
        "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
        "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
        "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
        "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
        "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
        "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
        "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
        "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
        "hair drier", "toothbrush"
    };
```

build the demo:

```shell
mkdir build
cd build
cmake ..
make
```

Then run the demo:

```shell
./yolov6 ../you.engine -i image_path
```

# Evaluate the performance
 You can evaluate the performance of the TensorRT model.
 ```
 python deploy/TensorRT/eval_yolo_trt.py \
    --imgs_dir /path/to/images/val \
    --labels_dir /path/to/labels/val\
    --annotations /path/to/coco/format/annotation/file \ --batch 1 \
    --img_size 640 \
    --model /path/to/tensorrt/model \
    --do_pr_metric --is_coco
 ```
Tips:
`--is_coco`:  if you are evaluating the COCO dataset, add this, if not, do not add this parameter.
`--do_pr_metric`: If you want to get PR metric, add this.

For example:
```
python deploy/TensorRT/eval_yolo_trt.py \
 --imgs_dir /workdir/datasets/coco/images/val2017/ \
 --labels_dir /workdir/datasets/coco/labels/val2017\
 --annotations /workdir/datasets/coco/annotations/instances_val2017.json \
 --batch 1 \
 --img_size 640 \
 --model weights/yolov6n.trt \
 --do_pr_metric --is_coco

```
